{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nainapandey96/digit-recognizer-cnn?scriptVersionId=106437813\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"94e7ca9d","metadata":{"papermill":{"duration":0.016134,"end_time":"2022-09-24T15:44:06.452059","exception":false,"start_time":"2022-09-24T15:44:06.435925","status":"completed"},"tags":[]},"source":["# CONVULATION NEURAL NETWORK FROM SRATCH ON MNIST HANDWRITTEN DIGIT\n","\n","A deep neural network is used for handling large datasets. We have many kinds of ANN for specific tasks like using LSTM for NLP. Similarly, we have a neural network that works for images. \n","\n","The AI system, which became known as AlexNet (named after its main creator, Alex Krizhevsky), won the 2012 ImageNet computer vision contest with an amazing 85 percent accuracy. The runner-up scored a modest 74 percent on the test.\n","At the heart of AlexNet were Convolutional Neural Networks a special type of neural network that roughly imitates human vision. Over the years CNNs have become a very important part of many Computer Vision applications. So let's take a look at the workings of CNNs.\n","\n","\n","## HUMAN VISUAL AND CNN\n","\n","![](http://cdn-images-1.medium.com/max/1200/1*lHJ0dsKEHGgft4tvGSdEEQ.png)\n","\n","The idea of CNN was neurobiological motivated by the findings of locally sensitive and orientation-selective nerve cells in the visual cortex. Inventors of CNN designed a network structure that implicitly extracts relevant features. they are special kind of neural network. \n","![](https://cdn-images-1.medium.com/max/1200/1*5jHSOTMYNHtwZz-zoPDOBA.png)\n","\n","In mathematics **convolution** is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by the other.\n","\n","\n","The core idea behind the CNN:\n","\n","* Local Connections: Represent how each set of neurons in a cluster disconnected to each other, which in turn represents set of features.\n","* Layering: Represents the hierarchy in features that are learned.\n","* Spatial Invariance: Represents the capability of CNN to learn abstractions invariant of size, contrast, rotation and variation.\n","\n","Some famous CNN are:\n","* LeNet, 1998\n","* AlexNet,2012\n","* VGGNet, 2014\n","* ResNet, 2015\n","![](https://cdn-images-1.medium.com/max/1200/1*WIualtW3hcZrTJ271nCwHQ.png)\n","\n","So with this we are done with history of CNN and went through some famous CNN's. Lets get down its working.\n","\n","## Working of CNN\n","\n","Lets understand what is image first. Image is a matrix with pixel values. If image is gray scale it has only one plane with pixel values 0 or 1. If image is in RGB, then it will have three color channels. It means it will have 3 planes.\n","![](https://cdn-images-1.medium.com/max/1200/0*VICTxt7DJHFzZHln.png)\n","CNN works of specific details rather than the whole image. Its covinent and effective to represent a smaller region with fewer parameters, thereby reducing reducing computational complexity. \n","\n","![](https://cdn-images-1.medium.com/max/1200/1*Hdlq0QDTPgHjMwuI_nGweQ.png)\n","\n","CNN have what we call as convolution layer. It works as a filter above the image, applying which we get a convolved feature. This feature is passed on to next layer.\n","![](https://cdn-images-1.medium.com/max/1200/0*48GVrt_bOvmgk01q.gif)\n","\n","Filters can be considered as network parameters to be learned. If you change the stride size, the convoluted output will vary(only outputting intense pixel). When RGB image is used as input to CNN, the depth of filter is always equal to the depth of image (3 in case of RGB and 1 in grayscale).\n","\n","## What is Pooling Layer?\n","\n","The pooling layer gradually reduces the spatial size of each matrix within the feature map such that the amount of parameters and computation is reduced in the network. The most common used pooling approach is max pooling.\n","\n","![](https://cdn-images-1.medium.com/max/1200/1*3yaRJLXL7wLO30lO6d7RHQ.png)\n","\n","The **CNN Architecture** compromises multiple combinations of convolution and pooling layers. Resultant image is smaller than the original image. the reduced image from these layers (convolution+pooling) is then passed through the activation function.\n","\n","![](https://cdn-images-1.medium.com/max/1200/1*lcw96OJTT8Ec5gMLucDKVA.png)\n","\n","So with this we are done with theory. There are other things for you to ponder upon like deep CNN or how these networks are different from fully connected ANN? Lets jump into implementation."]},{"cell_type":"code","execution_count":1,"id":"b1a3c8ba","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-24T15:44:06.494582Z","iopub.status.busy":"2022-09-24T15:44:06.493833Z","iopub.status.idle":"2022-09-24T15:44:06.500185Z","shell.execute_reply":"2022-09-24T15:44:06.500759Z","shell.execute_reply.started":"2022-05-08T06:36:58.568728Z"},"papermill":{"duration":0.031761,"end_time":"2022-09-24T15:44:06.501066","exception":false,"start_time":"2022-09-24T15:44:06.469305","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/digit-recognizer/sample_submission.csv\n","/kaggle/input/digit-recognizer/train.csv\n","/kaggle/input/digit-recognizer/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"316abb7f","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:06.535201Z","iopub.status.busy":"2022-09-24T15:44:06.534417Z","iopub.status.idle":"2022-09-24T15:44:12.0226Z","shell.execute_reply":"2022-09-24T15:44:12.022113Z","shell.execute_reply.started":"2022-09-24T13:57:41.527429Z"},"papermill":{"duration":5.505454,"end_time":"2022-09-24T15:44:12.022775","exception":false,"start_time":"2022-09-24T15:44:06.517321","status":"completed"},"tags":[]},"outputs":[],"source":["#Import libraries\n","\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.utils import to_categorical\n","import pandas as pd\n","import datetime\n","%matplotlib inline"]},{"cell_type":"code","execution_count":3,"id":"62766f18","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:12.058978Z","iopub.status.busy":"2022-09-24T15:44:12.058293Z","iopub.status.idle":"2022-09-24T15:44:17.056297Z","shell.execute_reply":"2022-09-24T15:44:17.055751Z","shell.execute_reply.started":"2022-09-24T13:52:44.282084Z"},"papermill":{"duration":5.017685,"end_time":"2022-09-24T15:44:17.056451","exception":false,"start_time":"2022-09-24T15:44:12.038766","status":"completed"},"tags":[]},"outputs":[],"source":["df_train=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n","df_test=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')"]},{"cell_type":"code","execution_count":4,"id":"588c70c7","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:17.105621Z","iopub.status.busy":"2022-09-24T15:44:17.10491Z","iopub.status.idle":"2022-09-24T15:44:17.200613Z","shell.execute_reply":"2022-09-24T15:44:17.200142Z","shell.execute_reply.started":"2022-09-24T13:53:18.38252Z"},"papermill":{"duration":0.120143,"end_time":"2022-09-24T15:44:17.2008","exception":false,"start_time":"2022-09-24T15:44:17.080657","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(42000, 28, 28, 1)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["feature= df_train.drop('label', axis=1)\n","target= df_train.label\n","feature_new= feature.values.reshape(-1,28,28,1)\n","df_test_new=df_test.values.reshape(-1,28,28,1)\n","feature_new.shape"]},{"cell_type":"markdown","id":"a0e998da","metadata":{"papermill":{"duration":0.015009,"end_time":"2022-09-24T15:44:17.231838","exception":false,"start_time":"2022-09-24T15:44:17.216829","status":"completed"},"tags":[]},"source":["We will convert target variable to categorical using one hot encoding. We have 10 classes. to_categorical() will work for you. We will convert integers to float and normalize the data by dividing all values by 255.0. Why 255? That is something for you to find out."]},{"cell_type":"code","execution_count":5,"id":"384f450e","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:17.268159Z","iopub.status.busy":"2022-09-24T15:44:17.267162Z","iopub.status.idle":"2022-09-24T15:44:17.429858Z","shell.execute_reply":"2022-09-24T15:44:17.429345Z","shell.execute_reply.started":"2022-09-24T13:54:50.672529Z"},"papermill":{"duration":0.182721,"end_time":"2022-09-24T15:44:17.430006","exception":false,"start_time":"2022-09-24T15:44:17.247285","status":"completed"},"tags":[]},"outputs":[],"source":["feature_new= feature_new.astype('float32')\n","df_test_new=df_test_new.astype('float32')\n","#normalizing\n","feature_new= feature_new/255\n","df_test_new=df_test_new/255"]},{"cell_type":"code","execution_count":6,"id":"3ea829c4","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:17.466857Z","iopub.status.busy":"2022-09-24T15:44:17.466258Z","iopub.status.idle":"2022-09-24T15:44:17.469448Z","shell.execute_reply":"2022-09-24T15:44:17.46986Z","shell.execute_reply.started":"2022-09-24T13:55:20.583123Z"},"papermill":{"duration":0.024015,"end_time":"2022-09-24T15:44:17.470002","exception":false,"start_time":"2022-09-24T15:44:17.445987","status":"completed"},"tags":[]},"outputs":[],"source":["target_new=to_categorical(target, num_classes=10)"]},{"cell_type":"code","execution_count":7,"id":"e199379d","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:17.508911Z","iopub.status.busy":"2022-09-24T15:44:17.508161Z","iopub.status.idle":"2022-09-24T15:44:17.732214Z","shell.execute_reply":"2022-09-24T15:44:17.732888Z","shell.execute_reply.started":"2022-09-24T13:55:29.2815Z"},"papermill":{"duration":0.247445,"end_time":"2022-09-24T15:44:17.733052","exception":false,"start_time":"2022-09-24T15:44:17.485607","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fdf7d758510>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.imshow(feature_new[0])"]},{"cell_type":"markdown","id":"43714f3e","metadata":{"papermill":{"duration":0.016585,"end_time":"2022-09-24T15:44:17.766237","exception":false,"start_time":"2022-09-24T15:44:17.749652","status":"completed"},"tags":[]},"source":["Now we are done with preparing our feature and target. We will begin now with our baseline model. Our baseline model will have two parts:\n","1. Base CNN model with one Conv2D and one pooling layer.\n","2. Another part is a classifier to predict the class."]},{"cell_type":"code","execution_count":8,"id":"b476f848","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:44:17.806789Z","iopub.status.busy":"2022-09-24T15:44:17.806216Z","iopub.status.idle":"2022-09-24T15:45:20.269092Z","shell.execute_reply":"2022-09-24T15:45:20.269547Z","shell.execute_reply.started":"2022-09-24T14:39:44.222679Z"},"papermill":{"duration":62.485905,"end_time":"2022-09-24T15:45:20.269732","exception":false,"start_time":"2022-09-24T15:44:17.783827","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-24 15:44:17.898644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:17.998092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:17.999166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:18.001401: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-09-24 15:44:18.002472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:18.003240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:18.003916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:20.073870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:20.074713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:20.075466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-09-24 15:44:20.076120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2022-09-24 15:44:21.018731: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n"]},{"name":"stderr","output_type":"stream","text":["2022-09-24 15:44:22.286378: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["1313/1313 [==============================] - 11s 3ms/step - loss: 0.5591 - accuracy: 0.8473\n","Epoch 2/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.2518 - accuracy: 0.9253\n","Epoch 3/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.1955 - accuracy: 0.9421\n","Epoch 4/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.1607 - accuracy: 0.9521\n","Epoch 5/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.1360 - accuracy: 0.9604\n","Epoch 6/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.1172 - accuracy: 0.9649\n","Epoch 7/15\n","1313/1313 [==============================] - 3s 2ms/step - loss: 0.1042 - accuracy: 0.9690\n","Epoch 8/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0933 - accuracy: 0.9722\n","Epoch 9/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0852 - accuracy: 0.9743\n","Epoch 10/15\n","1313/1313 [==============================] - 3s 2ms/step - loss: 0.0777 - accuracy: 0.9764\n","Epoch 11/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0714 - accuracy: 0.9784\n","Epoch 12/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.0667 - accuracy: 0.9796\n","Epoch 13/15\n","1313/1313 [==============================] - 3s 3ms/step - loss: 0.0612 - accuracy: 0.9815\n","Epoch 14/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0576 - accuracy: 0.9823\n","Epoch 15/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0538 - accuracy: 0.9845\n"]}],"source":["##Baseline model \n","model= keras.Sequential([\n","    keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(100,activation='relu'),\n","    keras.layers.Dense(10,activation='softmax')   \n","])\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","model.compile(optimizer='SGD',\n","              loss='CategoricalCrossentropy',\n","              metrics=['accuracy']\n","             )\n","history=model.fit(feature_new,target_new, epochs=15)"]},{"cell_type":"markdown","id":"f33a51fc","metadata":{"papermill":{"duration":0.316382,"end_time":"2022-09-24T15:45:20.904792","exception":false,"start_time":"2022-09-24T15:45:20.58841","status":"completed"},"tags":[]},"source":["with baseline we are getting 98.20% accuracy. So now we will tinker with our model and use some other layers to see if our accuracy increases."]},{"cell_type":"markdown","id":"cc4ba616","metadata":{"papermill":{"duration":0.316537,"end_time":"2022-09-24T15:45:21.542123","exception":false,"start_time":"2022-09-24T15:45:21.225586","status":"completed"},"tags":[]},"source":["## Batch Normalization\n","\n","First thing we will use is BatchNormalization(). Why BatchNormalization?\n","\n","Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n","It is used to perform the standardizing and normalizing operations on the input of a layer coming from a previous layer. A typical neural network is trained using a collected set of input data called batch. Similarly, the normalizing process in batch normalization takes place in batches, not as a single input.\n","So lets implement it with our baseline and check if it makes any difference.\n"]},{"cell_type":"code","execution_count":9,"id":"fe6be19c","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:45:22.192455Z","iopub.status.busy":"2022-09-24T15:45:22.191568Z","iopub.status.idle":"2022-09-24T15:46:26.623736Z","shell.execute_reply":"2022-09-24T15:46:26.622986Z","shell.execute_reply.started":"2022-09-24T14:50:10.194463Z"},"papermill":{"duration":64.763243,"end_time":"2022-09-24T15:46:26.623882","exception":false,"start_time":"2022-09-24T15:45:21.860639","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","1313/1313 [==============================] - 5s 3ms/step - loss: 0.1831 - accuracy: 0.9479\n","Epoch 2/15\n","1313/1313 [==============================] - 5s 3ms/step - loss: 0.0773 - accuracy: 0.9792\n","Epoch 3/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0545 - accuracy: 0.9858\n","Epoch 4/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0433 - accuracy: 0.9887\n","Epoch 5/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0349 - accuracy: 0.9912\n","Epoch 6/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0281 - accuracy: 0.9934\n","Epoch 7/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0234 - accuracy: 0.9945\n","Epoch 8/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0192 - accuracy: 0.9961\n","Epoch 9/15\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0160 - accuracy: 0.9973\n","Epoch 10/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0147 - accuracy: 0.9977\n","Epoch 11/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9982\n","Epoch 12/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0111 - accuracy: 0.9985\n","Epoch 13/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0098 - accuracy: 0.9987\n","Epoch 14/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0090 - accuracy: 0.9990\n","Epoch 15/15\n","1313/1313 [==============================] - 4s 3ms/step - loss: 0.0073 - accuracy: 0.9994\n"]}],"source":["model_batch= keras.Sequential([\n","    keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(100,activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(10,activation='softmax')   \n","])\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","model_batch.compile(optimizer='SGD',\n","              loss='CategoricalCrossentropy',\n","              metrics=['accuracy']\n","             )\n","history=model_batch.fit(feature_new,target_new, epochs=15)"]},{"cell_type":"markdown","id":"48131542","metadata":{"papermill":{"duration":0.680562,"end_time":"2022-09-24T15:46:27.998572","exception":false,"start_time":"2022-09-24T15:46:27.31801","status":"completed"},"tags":[]},"source":["So thats a tremendous improvement in our accuracy by just using batch normalization. \n","\n","We will try to implement VGG like pattern and see what our results will be. For that architecture is something like\n","Input layer\n","* Batch Normalization\n","* 2 layers of Conv2D\n","* 1 layer of pooling\n","* and our classifier"]},{"cell_type":"code","execution_count":10,"id":"a3c435e5","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:46:29.397098Z","iopub.status.busy":"2022-09-24T15:46:29.390159Z","iopub.status.idle":"2022-09-24T15:47:52.230356Z","shell.execute_reply":"2022-09-24T15:47:52.229858Z","shell.execute_reply.started":"2022-09-24T14:57:46.298608Z"},"papermill":{"duration":83.53855,"end_time":"2022-09-24T15:47:52.230497","exception":false,"start_time":"2022-09-24T15:46:28.691947","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1313/1313 [==============================] - 6s 5ms/step - loss: 0.1480 - accuracy: 0.9610\n","Epoch 2/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0588 - accuracy: 0.9841\n","Epoch 3/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0399 - accuracy: 0.9900\n","Epoch 4/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0299 - accuracy: 0.9929\n","Epoch 5/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0239 - accuracy: 0.9944\n","Epoch 6/10\n","1313/1313 [==============================] - 6s 4ms/step - loss: 0.0179 - accuracy: 0.9962\n","Epoch 7/10\n","1313/1313 [==============================] - 6s 4ms/step - loss: 0.0144 - accuracy: 0.9974\n","Epoch 8/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0109 - accuracy: 0.9986\n","Epoch 9/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0094 - accuracy: 0.9988\n","Epoch 10/10\n","1313/1313 [==============================] - 5s 4ms/step - loss: 0.0071 - accuracy: 0.9993\n"]}],"source":["#VGG like pattern\n","model_vg= keras.Sequential([\n","    keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv2D(64,(3,3), activation='relu'),\n","    keras.layers.Conv2D(64,(3,3), activation='relu'),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(100,activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(10,activation='softmax')   \n","])\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","model_vg.compile(optimizer='SGD',\n","              loss='CategoricalCrossentropy',\n","              metrics=['accuracy']\n","             )\n","history=model_vg.fit(feature_new,target_new, epochs=10)"]},{"cell_type":"code","execution_count":11,"id":"98ac7d14","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:47:54.356112Z","iopub.status.busy":"2022-09-24T15:47:54.354876Z","iopub.status.idle":"2022-09-24T15:47:55.818844Z","shell.execute_reply":"2022-09-24T15:47:55.818324Z","shell.execute_reply.started":"2022-09-24T15:24:36.372493Z"},"papermill":{"duration":2.578613,"end_time":"2022-09-24T15:47:55.818991","exception":false,"start_time":"2022-09-24T15:47:53.240378","status":"completed"},"tags":[]},"outputs":[],"source":["test_predict=model_vg.predict(df_test_new)"]},{"cell_type":"code","execution_count":12,"id":"2e7fe485","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:47:57.892478Z","iopub.status.busy":"2022-09-24T15:47:57.891804Z","iopub.status.idle":"2022-09-24T15:47:57.894819Z","shell.execute_reply":"2022-09-24T15:47:57.895245Z","shell.execute_reply.started":"2022-09-24T15:16:06.673458Z"},"papermill":{"duration":1.053803,"end_time":"2022-09-24T15:47:57.895401","exception":false,"start_time":"2022-09-24T15:47:56.841598","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([[2.8319146e-06, 1.3214886e-07, 9.9998426e-01, ..., 1.6143829e-06,\n","        1.1277303e-06, 1.0240271e-06],\n","       [9.9768472e-01, 4.0521434e-05, 1.3845240e-03, ..., 1.0492284e-04,\n","        5.1360614e-05, 4.8459960e-06],\n","       [5.6264639e-06, 3.8096528e-06, 1.4444838e-03, ..., 4.6333034e-06,\n","        4.0340523e-04, 9.9801207e-01],\n","       ...,\n","       [8.5132194e-07, 5.4268385e-06, 4.3064242e-06, ..., 1.1003532e-05,\n","        1.2407074e-05, 5.4650113e-06],\n","       [1.3601066e-03, 1.3388912e-05, 1.1827161e-05, ..., 1.5115459e-05,\n","        5.3224387e-05, 9.9801540e-01],\n","       [6.6732184e-08, 2.8184919e-08, 9.9999690e-01, ..., 1.5161012e-08,\n","        1.6992926e-06, 2.3713775e-07]], dtype=float32)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test_predict"]},{"cell_type":"code","execution_count":13,"id":"de8ebd34","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:47:59.951506Z","iopub.status.busy":"2022-09-24T15:47:59.950651Z","iopub.status.idle":"2022-09-24T15:47:59.956905Z","shell.execute_reply":"2022-09-24T15:47:59.956396Z","shell.execute_reply.started":"2022-09-24T15:24:42.568654Z"},"papermill":{"duration":1.04676,"end_time":"2022-09-24T15:47:59.95704","exception":false,"start_time":"2022-09-24T15:47:58.91028","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([2, 0, 9, 9, 3])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["predict=np.argmax(test_predict, axis=1)\n","predict[:5]"]},{"cell_type":"code","execution_count":14,"id":"5840e54f","metadata":{"execution":{"iopub.execute_input":"2022-09-24T15:48:02.249499Z","iopub.status.busy":"2022-09-24T15:48:02.248861Z","iopub.status.idle":"2022-09-24T15:48:02.291323Z","shell.execute_reply":"2022-09-24T15:48:02.291796Z","shell.execute_reply.started":"2022-09-24T15:24:47.369843Z"},"papermill":{"duration":1.088594,"end_time":"2022-09-24T15:48:02.291956","exception":false,"start_time":"2022-09-24T15:48:01.203362","status":"completed"},"tags":[]},"outputs":[],"source":["submission=pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\n","submission['Label']=predict\n","submission.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","id":"c33fe4af","metadata":{"papermill":{"duration":0.997903,"end_time":"2022-09-24T15:48:04.281289","exception":false,"start_time":"2022-09-24T15:48:03.283386","status":"completed"},"tags":[]},"source":["so with this we have learnt so many things today. We learnt about CNN , its history and went through its implementation. There is so much more about CNN , I mean there are literally books written on one topic. But this article will give you a start on CNN. I hope this article gave a basic start point for computer vision. \n","Thank you all for reading my article.\n","\n","\n","Follow me on [@NancyPandey](https://www.linkedin.com/in/nancy-pandey-08595987/)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":249.721311,"end_time":"2022-09-24T15:48:08.235031","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-24T15:43:58.51372","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}